{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qAU1riDdbhn2",
    "outputId": "a9c11136-7f30-46e2-a374-2ce16c2b179f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stackapi in /Users/bigmac/opt/anaconda3/lib/python3.8/site-packages (0.2.0)\n",
      "Requirement already satisfied: six in /Users/bigmac/opt/anaconda3/lib/python3.8/site-packages (from stackapi) (1.15.0)\n",
      "Requirement already satisfied: requests in /Users/bigmac/opt/anaconda3/lib/python3.8/site-packages (from stackapi) (2.25.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/bigmac/opt/anaconda3/lib/python3.8/site-packages (from requests->stackapi) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/bigmac/opt/anaconda3/lib/python3.8/site-packages (from requests->stackapi) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/bigmac/opt/anaconda3/lib/python3.8/site-packages (from requests->stackapi) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/bigmac/opt/anaconda3/lib/python3.8/site-packages (from requests->stackapi) (4.0.0)\n"
     ]
    }
   ],
   "source": [
    "# documentation for the API\n",
    "# https://stackapi.readthedocs.io/en/latest/\n",
    "\n",
    "!pip3 install stackapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QWwXrkx5Jiiw",
    "outputId": "d8f05f31-2a81-4747-d798-e0cfedc650b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: unable to send email\n"
     ]
    }
   ],
   "source": [
    "##import required libraries\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from stackapi import StackAPI # import the API wrapper\n",
    "from stackapi import StackAPIError # import error methods for debugging\n",
    "\n",
    "# connect to the stackoverflow API using python wrapper\n",
    "def stackoverflow_connect():\n",
    "  try:\n",
    "    # create a SITE object to query upon\n",
    "    SITE = StackAPI('stackoverflow')\n",
    "    SITE.page_size = 100\n",
    "    SITE.max_pages=50 # this number would have to be tweaked\n",
    "  except StackAPIError as e:\n",
    "    print(e.message)\n",
    "  return SITE\n",
    "\n",
    "# get the json object for the current month \n",
    "def fetch_questions_JSON(SITE):\n",
    "  # month_begin = int(datetime.datetime.now().replace(day = 1).timestamp())   # get the timestamp of the beginning of current month based on when the query is run  \n",
    "  now = int(datetime.datetime.now().timestamp())   # get the timestamp of the current times based on when the query is run\n",
    "  month_begin = int((datetime.datetime.now() - datetime.timedelta(30)).timestamp()) # use a timedelta to get the data 30 days ago from current date\n",
    "\n",
    "  # get a JSON load of all the question in a timeframe ** \n",
    "  questions = SITE.fetch('questions' , fromdate = month_begin , todate = now\n",
    "                        #  , min = 20\n",
    "                         , tagged = 'julia'\n",
    "                        , sort = 'votes')\n",
    "  return questions \n",
    "\n",
    "# read the json file into a pandas DF\n",
    "def json_df_redux(questions):\n",
    "  # pull the items from the JSON questions field \n",
    "  df = pd.json_normalize(questions['items'])\n",
    "  return df\n",
    "\n",
    "\n",
    "# upload the raw df into database using spark (intentionally left blank)\n",
    "def load_raw_df_to_db(df):\n",
    "  # conver the pandas df into spark df \n",
    "  raw_spark_df = spark.createDataFrame(df)\n",
    "  mode = \"overwrite\"\n",
    "  url = \"jdbc:redshift://localhost:5432/etl_pipeline\"\n",
    "  properties = {\"user\": \"<username>\",\n",
    "                \"password\": \"<password>\",\n",
    "                \"driver\": \"org.redshift.Driver\"\n",
    "                }\n",
    "  raw_spark_df.write.jdbc(url=url,\n",
    "                table = \"raw_stackoverflow_questions\",\n",
    "                mode = mode,\n",
    "                properties = properties)\n",
    "\n",
    "# lets transform the questions pandas df to make some more insights about the tags\n",
    "\n",
    "def tag_enrichment(df):\n",
    "  df1 = df.explode('tags') # we are explosing the tags column into rows to get each tag detail\n",
    "  monthly_top_20_tags = df1['tags'].value_counts()[:20]\n",
    "  monthly_top_20_tags = monthly_top_20_tags.to_frame()\n",
    "  return monthly_top_20_tags\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    SITE = stackoverflow_connect()\n",
    "    questions = fetch_questions_JSON(SITE)\n",
    "    df = json_df_redux(questions)\n",
    "    # load_raw_df_to_db(df) # optional step to push the raw dataframe into database of choice\n",
    "    top_tags = tag_enrichment(df)\n",
    "    email_tag_data(top_tags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcSbLBqEgjFM"
   },
   "source": [
    "Test the functions locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "RJslaX_ke1eM"
   },
   "outputs": [],
   "source": [
    "from stackapi import StackAPI # import the API wrapper\n",
    "import datetime\n",
    "\n",
    "\n",
    "# create a SITE object to query upon\n",
    "SITE = StackAPI('stackoverflow')\n",
    "# SITE.page_size = 100\n",
    "# SITE.max_pages=100 # this number would have to be tweaked\n",
    "\n",
    "# now = int(datetime.datetime.now().timestamp())  \n",
    "# month_begin = int((datetime.datetime.now() - datetime.timedelta(9999)).timestamp())\n",
    "\n",
    "# get a JSON load of all the question in a timeframe ** \n",
    "questions = SITE.fetch('questions' \n",
    "                    # , fromdate = month_begin , todate = now\n",
    "                    # , min = 20\n",
    "                     , tagged = 'julia'\n",
    "                    , sort = 'votes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xxfh3x78hVmh"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.json_normalize(questions['items'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Packt Assessment - Tajal",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
